{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r0J-_CN43iFB"
      },
      "source": [
        "# Transpiling a Tensorflow model to build on top"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg7DGGmT4iuF"
      },
      "source": [
        "Transpile a ``keras`` model to ``torch`` and build a new model around it.\n",
        "\n",
        "⚠️ If you are running this notebook in Colab, you will have to install Ivy and some dependencies manually. You can do so by running the cell below ⬇️\n",
        "\n",
        "If you want to run the notebook locally but don't have Ivy installed just yet, you can check out the [Get Started section of the docs.](https://unify.ai/docs/ivy/overview/get_started.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xACzHp10hdTX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ivy in /workspaces/ivy (0.0.4.0)\n",
            "Requirement already satisfied: numpy in /opt/fw/mxnet (from ivy) (1.26.1)\n",
            "Requirement already satisfied: einops in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (0.7.0)\n",
            "Requirement already satisfied: psutil in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (5.9.6)\n",
            "Requirement already satisfied: termcolor in /opt/fw/tensorflow (from ivy) (2.3.0)\n",
            "Requirement already satisfied: colorama in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (0.4.6)\n",
            "Requirement already satisfied: packaging in /opt/fw/tensorflow (from ivy) (23.2)\n",
            "Requirement already satisfied: nvidia-ml-py in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (12.535.108)\n",
            "Requirement already satisfied: diskcache in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (5.6.3)\n",
            "Requirement already satisfied: google-auth in /opt/fw/tensorflow (from ivy) (2.23.3)\n",
            "Requirement already satisfied: urllib3<2.0 in /root/.local/lib/python3.10/site-packages (from ivy) (1.26.18)\n",
            "Requirement already satisfied: requests in /opt/fw/mxnet (from ivy) (2.31.0)\n",
            "Requirement already satisfied: pyvis in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (0.3.2)\n",
            "Requirement already satisfied: dill in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (0.3.7)\n",
            "Requirement already satisfied: astunparse in /opt/fw/tensorflow (from ivy) (1.6.3)\n",
            "Requirement already satisfied: ml-dtypes in /opt/fw/tensorflow (from ivy) (0.2.0)\n",
            "Requirement already satisfied: cloudpickle in /opt/fw/tensorflow (from ivy) (3.0.0)\n",
            "Requirement already satisfied: gast in /opt/fw/tensorflow (from ivy) (0.5.4)\n",
            "Requirement already satisfied: tqdm in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (4.66.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/fw/tensorflow (from astunparse->ivy) (0.41.3)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /opt/fw/tensorflow (from astunparse->ivy) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/fw/tensorflow (from google-auth->ivy) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/fw/tensorflow (from google-auth->ivy) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/fw/tensorflow (from google-auth->ivy) (4.9)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from pyvis->ivy) (8.17.1)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /opt/fw/torch (from pyvis->ivy) (3.1.2)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from pyvis->ivy) (3.0.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /opt/fw/torch (from pyvis->ivy) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/fw/mxnet (from requests->ivy) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/fw/mxnet (from requests->ivy) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/fw/mxnet (from requests->ivy) (2023.7.22)\n",
            "Requirement already satisfied: decorator in /opt/fw/tensorflow (from ipython>=5.3.0->pyvis->ivy) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (3.0.39)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /opt/fw/jax (from ipython>=5.3.0->pyvis->ivy) (2.16.1)\n",
            "Requirement already satisfied: stack-data in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (5.13.0)\n",
            "Requirement already satisfied: exceptiongroup in /opt/fw/paddle (from ipython>=5.3.0->pyvis->ivy) (1.1.3)\n",
            "Requirement already satisfied: pexpect>4.3 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (4.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/fw/tensorflow (from jinja2>=2.9.6->pyvis->ivy) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/fw/tensorflow (from pyasn1-modules>=0.2.1->google-auth->ivy) (0.5.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis->ivy) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis->ivy) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.3.0->pyvis->ivy) (0.2.9)\n",
            "Requirement already satisfied: executing>=1.2.0 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis->ivy) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis->ivy) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis->ivy) (0.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install ivy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GQCDMTkx46Wm"
      },
      "source": [
        "In Transpile Any Model we have seen how to transpile a torch model, now let's do the same with a model from keras transpiling a model from Keras to Torch and building a classifier on top of the resulting module.\n",
        "\n",
        "As usual, let's start with the imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "21E0BUCSl6iu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-02 06:17:44.597955: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import ivy\n",
        "import torch\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5-mJlrhz5SBi"
      },
      "source": [
        "Now, instead of building our own Keras model, we will get one directly from Keras.\n",
        "\n",
        "In this case, we are going to use a EfficientNet. We can download the pretrained weights with `weights=\"imagenet\"` and set `include_top=False` to only retrieve the feature extractor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v523P9hGqf-Y",
        "outputId": "7b1da773-d0cf-4c5e-d11f-73fff07b2178"
      },
      "outputs": [],
      "source": [
        "# Get a pretrained keras model\n",
        "eff_encoder = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
        "    include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3)\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wYT50RFT5mQx"
      },
      "source": [
        "Now, we will transpile the EfficientNet feature extractor to PyTorch using `ivy.transpile` and passing a sample `tf.tensor` with noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fML1OGasqs1o"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:To preserve the tracer and transpiler caches across multiple machines, ensure that the relative path of your projects from the .ivy folder is consistent across all machines. You can do this by adding .ivy to your home folder and placing all projects in the same place relative to the home folder on all machines.\n"
          ]
        },
        {
          "ename": "IvyException",
          "evalue": "backend must be one from ['jax', 'tensorflow', 'paddle', 'numpy', 'mxnet', 'torch']",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIvyException\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/workspaces/ivy/docs/demos/guides/03_transpiling_a_tf_model.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Borganic-space-enigma-vrp69g4g9qr2xr6x/workspaces/ivy/docs/demos/guides/03_transpiling_a_tf_model.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Transpile it into a torch.nn.Module with the corresponding parameters\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Borganic-space-enigma-vrp69g4g9qr2xr6x/workspaces/ivy/docs/demos/guides/03_transpiling_a_tf_model.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m noise \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Borganic-space-enigma-vrp69g4g9qr2xr6x/workspaces/ivy/docs/demos/guides/03_transpiling_a_tf_model.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m torch_eff_encoder \u001b[39m=\u001b[39m ivy\u001b[39m.\u001b[39;49mtranspile(eff_encoder, to\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtorch\u001b[39;49m\u001b[39m\"\u001b[39;49m, args\u001b[39m=\u001b[39;49m(noise,))\n",
            "File \u001b[0;32m/workspaces/ivy/ivy/compiler/compiler.py:157\u001b[0m, in \u001b[0;36mtranspile\u001b[0;34m(source, to, with_numpy, backend_compile, static_argnums, static_argnames, mode, graph_caching, stateful, arg_stateful_idxs, kwarg_stateful_idxs, args, kwargs, params_v, v, *objs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39mTranspiles Callable objects passed as arguments. If args and kwargs are specified,\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mtranspilation is performed eagerly, otherwise, transpilation will happen lazily.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mEither a transpiled Graph or a non-initialized LazyGraph.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_compiler\u001b[39;00m \u001b[39mimport\u001b[39;00m transpile \u001b[39mas\u001b[39;00m _transpile\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m _transpile(\n\u001b[1;32m    158\u001b[0m     \u001b[39m*\u001b[39;49mobjs,\n\u001b[1;32m    159\u001b[0m     source\u001b[39m=\u001b[39;49msource,\n\u001b[1;32m    160\u001b[0m     to\u001b[39m=\u001b[39;49mto,\n\u001b[1;32m    161\u001b[0m     with_numpy\u001b[39m=\u001b[39;49mwith_numpy,\n\u001b[1;32m    162\u001b[0m     backend_compile\u001b[39m=\u001b[39;49mbackend_compile,\n\u001b[1;32m    163\u001b[0m     static_argnums\u001b[39m=\u001b[39;49mstatic_argnums,\n\u001b[1;32m    164\u001b[0m     static_argnames\u001b[39m=\u001b[39;49mstatic_argnames,\n\u001b[1;32m    165\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    166\u001b[0m     graph_caching\u001b[39m=\u001b[39;49mgraph_caching,\n\u001b[1;32m    167\u001b[0m     stateful\u001b[39m=\u001b[39;49mstateful,\n\u001b[1;32m    168\u001b[0m     arg_stateful_idxs\u001b[39m=\u001b[39;49marg_stateful_idxs,\n\u001b[1;32m    169\u001b[0m     kwarg_stateful_idxs\u001b[39m=\u001b[39;49mkwarg_stateful_idxs,\n\u001b[1;32m    170\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    171\u001b[0m     kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m    172\u001b[0m     params_v\u001b[39m=\u001b[39;49mparams_v,\n\u001b[1;32m    173\u001b[0m     v\u001b[39m=\u001b[39;49mv,\n\u001b[1;32m    174\u001b[0m )\n",
            "File \u001b[0;32mDM.pyx:210\u001b[0m, in \u001b[0;36mDM.transpile\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mDM.pyx:55\u001b[0m, in \u001b[0;36mDM._to_target_framework\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/workspaces/ivy/ivy/utils/backend/handler.py:65\u001b[0m, in \u001b[0;36mprevent_access_locally.<locals>._prevent_access_locally\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m ivy\u001b[39m.\u001b[39mis_local():\n\u001b[1;32m     64\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCalling \u001b[39m\u001b[39m{\u001b[39;00mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is not allowed on this object.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/workspaces/ivy/ivy/utils/backend/handler.py:354\u001b[0m, in \u001b[0;36mset_backend\u001b[0;34m(backend, dynamic)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39m@prevent_access_locally\u001b[39m\n\u001b[1;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_backend\u001b[39m(backend: \u001b[39mstr\u001b[39m, dynamic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    331\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m    Set `backend` to be the global backend.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39m    <class 'jaxlib.xla_extension.ArrayImpl'>\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     ivy\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49massertions\u001b[39m.\u001b[39;49mcheck_false(\n\u001b[1;32m    355\u001b[0m         \u001b[39misinstance\u001b[39;49m(backend, \u001b[39mstr\u001b[39;49m) \u001b[39mand\u001b[39;49;00m backend \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m _backend_dict,\n\u001b[1;32m    356\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbackend must be one from \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mlist\u001b[39;49m(_backend_dict\u001b[39m.\u001b[39;49mkeys())\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m     )\n\u001b[1;32m    359\u001b[0m     \u001b[39m# update the global dict with the new backend\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[39mwith\u001b[39;00m ivy\u001b[39m.\u001b[39mlocks[\u001b[39m\"\u001b[39m\u001b[39mbackend_setter\u001b[39m\u001b[39m\"\u001b[39m]:\n",
            "File \u001b[0;32m/workspaces/ivy/ivy/utils/assertions.py:122\u001b[0m, in \u001b[0;36mcheck_false\u001b[0;34m(expression, message)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_false\u001b[39m(expression, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpression must be False\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m expression:\n\u001b[0;32m--> 122\u001b[0m         \u001b[39mraise\u001b[39;00m ivy\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mIvyException(message)\n",
            "\u001b[0;31mIvyException\u001b[0m: backend must be one from ['jax', 'tensorflow', 'paddle', 'numpy', 'mxnet', 'torch']"
          ]
        }
      ],
      "source": [
        "# Transpile it into a torch.nn.Module with the corresponding parameters\n",
        "noise = tf.random.normal(shape=(1, 224, 224, 3))\n",
        "torch_eff_encoder = ivy.transpile(eff_encoder, to=\"torch\", args=(noise,))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "koZ4UL_N6NFW"
      },
      "source": [
        "To ensure that the transpilation has been correct, let's check with a new input in both frameworks. Keep in mind that all the functions called within torch_eff_encoder are now PyTorch functions 🔀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OhKUmJemLkh",
        "outputId": "dd77938a-c983-4e78-f403-778e8e85a0ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "x = np.random.random(size=(1, 224, 224, 3)).astype(np.float32)\n",
        "output_tf = eff_encoder(tf.constant(x, dtype=tf.float32))\n",
        "output_torch = torch_eff_encoder(torch.tensor(x))\n",
        "print(np.allclose(output_tf , output_torch.detach().numpy(), rtol=1e-1))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rqCjBz6k7Flv"
      },
      "source": [
        "Now, we can build or own classifier using the transpiled module as the feature extractor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95FCfYQPljsu"
      },
      "outputs": [],
      "source": [
        "class Classifier(torch.nn.Module):\n",
        "    def __init__(self, num_classes=20):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.encoder = torch_eff_encoder\n",
        "        self.fc = torch.nn.Linear(1280, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GC5J0wyH7MpK"
      },
      "source": [
        "And finally, we can use our new model! As we have mentioned in \"Learn the Basics\", the transpiled model is fully trainable in the target framework, so you can also fine-tune your transpiled modules or train them from the ground up! 📉"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghSeZ655lrAG",
        "outputId": "84d8aa53-53ec-4d3f-d120-47d2b7950977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> torch.Size([1, 7, 7, 20])\n"
          ]
        }
      ],
      "source": [
        "model = Classifier()\n",
        "x = torch.randn(1, 224, 224, 3)\n",
        "ret = model(x)\n",
        "print(type(ret), ret.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Round Up"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1IJy4ayl7WUW"
      },
      "source": [
        "That's it! Now you are ready to transpile any TensorFlow model, layer or trainable module and integrate it within PyTorch, but let's keep exploring how we can convert trainable modules from (and to!) other frameworks ➡️"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
