{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2MY4-M1zuhV"
      },
      "source": [
        "\n",
        "\n",
        "#Training a Sarcasm Detection Model using LSTM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-AgItE6z80t"
      },
      "source": [
        "## Download the Dataset\n",
        "\n",
        "First, you will download the JSON file and extract the contents into lists."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ivy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmjVpd_B7Bue",
        "outputId": "18b2ca70-4857-4db5-c969-7b53ef9f6d17"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k_Wlz9i10Dmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1956d0c-9e7f-4af3-e4e5-5dad0888c5c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-15 09:14:19--  https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.207, 74.125.23.207, 74.125.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘sarcasm.json’\n",
            "\n",
            "sarcasm.json        100%[===================>]   5.38M  5.33MB/s    in 1.0s    \n",
            "\n",
            "2024-03-15 09:14:20 (5.33 MB/s) - ‘sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Pr4R0I240GOh"
      },
      "outputs": [],
      "source": [
        "# Load the JSON file\n",
        "import json\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"./sarcasm.json\", 'r') as f:\n",
        "    datastore = json.load(f)\n",
        "\n",
        "# Initialize the lists\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "# Collect sentences and labels into the lists\n",
        "for item in datastore:\n",
        "    sentences.append(item['headline'])\n",
        "    labels.append(item['is_sarcastic'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN9-ojV55UCR"
      },
      "source": [
        "## Split the Dataset\n",
        "\n",
        "You will then split the lists into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "50H0ZrJf035i"
      },
      "outputs": [],
      "source": [
        "training_size = 20000\n",
        "\n",
        "# Split the sentences into training and testing sets\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "\n",
        "# Split the labels into training and testing sets\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYVNY4tE5YbN"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "Next, you will generate the vocabulary and padded sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hodsUZib1Ce7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "vocab_size = 10000\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "\n",
        "# Generate the word index dictionary\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Generate and pad the training sequences\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Generate and pad the testing sequences\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Convert the labels lists into numpy arrays\n",
        "training_labels = np.array(training_labels)\n",
        "testing_labels = np.array(testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jGwXGIXvFhXW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Parameters\n",
        "embedding_dim = 16 # Define the embedding dimension\n",
        "lstm_dim = 32 # Define the LSTM dimension\n",
        "dense_dim = 24 # Define the dense layer dimension\n",
        "NUM_EPOCHS = 10 # Define the number of epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sample input tensor"
      ],
      "metadata": {
        "id": "66rd_X78UL8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sequence length and feature dimension\n",
        "sequence_length = 32  # The number of timesteps in each input sample\n",
        "feature_dim = 16      # The dimensionality of the input features\n",
        "\n",
        "# Create a sample input tensor with random data\n",
        "# The shape is (batch_size, sequence_length, feature_dim)\n",
        "# 'batch_size' can be any integer, representing the number of samples\n",
        "sample_input = np.random.rand(1, max_length).astype(np.float32)\n",
        "\n",
        "# Convert the numpy array to a TensorFlow tensor\n",
        "sample_input_tensor = tf.convert_to_tensor(sample_input)"
      ],
      "metadata": {
        "id": "4vzCIcPY7fcy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ivy\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "JrtzgugW8peT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition with LSTM\n"
      ],
      "metadata": {
        "id": "Hkz8H0fHUQGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ivy\n",
        "\n",
        "class SarcasmDetectionModel(ivy.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_classes = num_classes\n",
        "        self._build()\n",
        "\n",
        "    def _build(self, *args, **kwargs):\n",
        "        self.embedding = ivy.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.lstm = ivy.LSTM(self.embedding_dim, self.hidden_dim)\n",
        "        self.fc1 = ivy.Linear(self.hidden_dim, self.num_classes)\n",
        "        self.fc2 = ivy.Linear(self.num_classes, 1)\n",
        "\n",
        "    def _forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        lstm_output, (hidden, _) = self.lstm(x)\n",
        "\n",
        "        # Ensure 'hidden' is a tensor before reshaping\n",
        "        if isinstance(hidden, list):\n",
        "            # This is just an example, you'll need to adjust this based on your actual data structure\n",
        "            hidden = hidden[0]  # Select the appropriate tensor from the list\n",
        "\n",
        "        x = ivy.reshape(hidden, (hidden.shape[0], -1))  # Flatten the output for the linear layer\n",
        "        x = ivy.relu(self.fc1(x))\n",
        "        logits = ivy.relu(self.fc2(x))  # Apply ReLU before final sigmoid\n",
        "        probs = ivy.sigmoid(logits)\n",
        "        return logits, probs\n",
        "\n",
        "# Example usage:\n",
        "# Assuming vocab_size=10000, embedding_dim=300, hidden_dim=256, num_classes=2 (sarcasm or not)\n",
        "model = SarcasmDetectionModel(10000, 300, 256, 2)\n",
        "print(\"Success\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v2-2sju67ah",
        "outputId": "83fc5a33-8003-4a50-888b-faccc0a84bd5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q dm-haiku\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UosU5TRAQ7j",
        "outputId": "27c47c66-d78b-4a2c-cd7d-96a7d6025832"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/371.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/371.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m368.6/371.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax"
      ],
      "metadata": {
        "id": "M4h9H4Lr8bgB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ivy.set_backend(\"jax\")\n",
        "# Define a random key for JAX\n",
        "key = jax.random.PRNGKey(0)\n",
        "\n",
        "# Generate a random tensor representing a batch of tokenized text data\n",
        "# Here, 'seq_length' is the length of your tokenized input sequence\n",
        "seq_length = 100  # Example sequence length\n",
        "x = jax.random.randint(key, shape=(1, seq_length), minval=0, maxval=10000)\n",
        "\n",
        "# Pass the tensor through the model to obtain logits and probabilities\n",
        "logits, probs = model(x)"
      ],
      "metadata": {
        "id": "T9dbYN3I7oCZ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for loading the dataset in batches\n",
        "def generate_batches(text_data, labels, dataset_size, batch_size=32):\n",
        "    if batch_size > dataset_size:\n",
        "        raise ivy.utils.exceptions.IvyError(\"Use a smaller batch size\")\n",
        "    for idx in range(0, dataset_size, batch_size):\n",
        "        yield text_data[idx : min(idx + batch_size, dataset_size)], labels[\n",
        "            idx : min(idx + batch_size, dataset_size)\n",
        "        ]\n",
        "\n",
        "# Helper function to get the number of correct predictions\n",
        "def num_correct(preds, labels):\n",
        "    return (preds.argmax(axis=1) == labels).sum().to_numpy().item()\n",
        "\n",
        "# Define a loss function\n",
        "def loss_fn(params):\n",
        "    v, model, x, y = params\n",
        "    logits, probs = model(x, v=v)\n",
        "    return (ivy.cross_entropy(y, ivy.softmax(logits)), logits)\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have training_padded, training_labels, testing_padded, and testing_labels defined\n",
        "dataset_size = len(training_padded)  # Replace with your actual dataset size\n",
        "batch_size = 32  # Or any other batch size that fits your training scheme\n",
        "\n",
        "# # Generate batches for training\n",
        "# for batch_x, batch_y in generate_batches(training_padded, training_labels, dataset_size, batch_size):\n",
        "#     # Here you would perform your training steps, e.g.:\n",
        "#     # - Forward pass\n",
        "#     # - Compute loss\n",
        "#     # - Backward pass\n",
        "#     # - Update weights\n",
        "#     pass\n"
      ],
      "metadata": {
        "id": "NIEPnyotBsl9"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Enable 64-bit mode in JAX\n",
        "jax.config.update('jax_enable_x64', True)\n"
      ],
      "metadata": {
        "id": "PWmcuOmJC6lI"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ivy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming SarcasmDetectionModel and other necessary functions are defined above\n",
        "\n",
        "# Train the model on GPU if it's available\n",
        "device = \"gpu:0\" if ivy.gpu_is_available() else \"cpu\"\n",
        "\n",
        "# Training hyperparameters\n",
        "optimizer = ivy.Adam(1e-4)\n",
        "batch_size = 4\n",
        "num_epochs = 20\n",
        "num_classes = 2  # For sarcasm detection, we typically have two classes: sarcastic and not sarcastic\n",
        "\n",
        "# Initialize the sarcasm detection model\n",
        "model = SarcasmDetectionModel(\n",
        "    vocab_size=10000,  # Size of your vocabulary\n",
        "    embedding_dim=300,  # Size of each word embedding\n",
        "    hidden_dim=256,  # Number of features in the hidden state of the LSTM\n",
        "    num_classes=num_classes,\n",
        ")\n",
        "\n",
        "# Assuming training_padded, training_labels, testing_padded, and testing_labels are already prepared\n",
        "training_data = training_padded\n",
        "training_labels = training_labels\n",
        "\n",
        "# Training loop\n",
        "def train(training_data, training_labels, epochs, model, device, num_classes=2, batch_size=32):\n",
        "    # Training metrics\n",
        "    epoch_loss = 0.0\n",
        "    metrics = []\n",
        "    dataset_size = len(training_data)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_correct = 0\n",
        "        train_loop = tqdm(\n",
        "            generate_batches(training_data, training_labels, len(training_data), batch_size=batch_size),\n",
        "            total=dataset_size // batch_size,\n",
        "            position=0,\n",
        "            leave=True,\n",
        "        )\n",
        "        for xbatch, ybatch in train_loop:\n",
        "            xbatch, ybatch = ivy.to_device(ivy.array(xbatch), device), ivy.to_device(ivy.array(ybatch), device)\n",
        "\n",
        "            # One-hot encode ybatch\n",
        "            ybatch_encoded = ivy.one_hot(ybatch, num_classes)\n",
        "\n",
        "            # Compute loss and gradients\n",
        "            loss, grads = ivy.execute_with_gradients(loss_fn, (model.v, model, xbatch, ybatch_encoded))\n",
        "\n",
        "            # Update model parameters\n",
        "            model.v = optimizer.step(model.v, grads)\n",
        "\n",
        "            batch_loss = ivy.to_numpy(loss[0]).mean().item()  # Batch mean loss\n",
        "            epoch_loss += batch_loss * xbatch.shape[0]\n",
        "            train_correct += num_correct(loss[1], ybatch)\n",
        "\n",
        "            train_loop.set_description(f\"Epoch [{epoch + 1:2d}/{epochs}]\")\n",
        "            train_loop.set_postfix(\n",
        "                running_loss=batch_loss,\n",
        "                accuracy_percentage=(train_correct / dataset_size) * 100,\n",
        "            )\n",
        "\n",
        "        epoch_loss = epoch_loss / dataset_size\n",
        "        training_accuracy = train_correct / dataset_size\n",
        "\n",
        "        metrics.append([epoch, epoch_loss, training_accuracy])\n",
        "\n",
        "        train_loop.write(\n",
        "            f\"\\nAverage training loss: {epoch_loss:.6f}, Train Correct: {train_correct}\",\n",
        "            end=\"\\n\",\n",
        "        )\n",
        "\n",
        "# Train the model\n",
        "train(\n",
        "    training_data,\n",
        "    training_labels,\n",
        "    num_epochs,\n",
        "    model,\n",
        "    device,\n",
        "    num_classes=num_classes,\n",
        "    batch_size=batch_size,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "oYfLSObBCLAN",
        "outputId": "68e2a453-6945-4200-910c-5d91b0eb5d03"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5000 [00:03<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IvyValueError",
          "evalue": "jax: execute_with_gradients: not enough values to unpack (expected 3, got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ivy/utils/exceptions.py\u001b[0m in \u001b[0;36m_handle_exceptions\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIvyException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ivy/func_wrapper.py\u001b[0m in \u001b[0;36m_handle_device\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m             )\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mivy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mivy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mivy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_soft_device_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ivy/functional/ivy/device.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ivy/func_wrapper.py\u001b[0m in \u001b[0;36m_handle_device\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mivy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mivy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mivy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_soft_device_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;31m# raise when arrays are on different devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ivy/functional/backends/jax/device.py\u001b[0m in \u001b[0;36mhandle_soft_device_variable\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_shifting_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ivy/functional/backends/jax/gradients.py\u001b[0m in \u001b[0;36mexecute_with_gradients\u001b[0;34m(func, xs, retain_grads, xs_grad_idxs, ret_grad_idxs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Getting the relevant outputs from the function return for gradient calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mret_grad_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_y_and_ret_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret_grad_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIvyValueError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-8f81985ea29d>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m train(\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-8f81985ea29d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training_data, training_labels, epochs, model, device, num_classes, batch_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Compute loss and gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mivy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_with_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mybatch_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Update model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ivy/utils/exceptions.py\u001b[0m in \u001b[0;36m_handle_exceptions\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIvyBackendException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             )\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0m_handle_exceptions_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mivy_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_exceptions_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ivy/utils/exceptions.py\u001b[0m in \u001b[0;36m_handle_exceptions_helper\u001b[0;34m(e, cls)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_exceptions_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0m_configure_stack_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_backend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0m_handle_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIvyValueError\u001b[0m: jax: execute_with_gradients: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9B91_Xvf1FFc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}